{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU-xwsG8NlrO",
        "outputId": "cbf320c6-304d-49e1-c838-15770276a4ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj9b9hvDMYTn",
        "outputId": "5b752c31-b8db-43cc-ab48-e81926c32fd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.38.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.8.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import numpy as np\n",
        "import os\n"
      ],
      "metadata": {
        "id": "dYXY78bjMft0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to your datasets\n",
        "train_data_dir = \"/content/drive/MyDrive/Teeth_Dataset/Training\"\n",
        "val_data_dir = \"/content/drive/MyDrive/Teeth_Dataset/Validation\"\n",
        "test_data_dir = \"/content/drive/MyDrive/Teeth_Dataset/Testing\"\n",
        "\n",
        "# Define Image Data Generators for Augmentation\n",
        "train_augment = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2)\n",
        "])\n",
        "\n",
        "# Load training dataset with augmentation\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    train_data_dir,\n",
        "    image_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    label_mode='categorical',\n",
        "    shuffle=True\n",
        ").map(lambda x, y: (train_augment(x), y))\n",
        "\n",
        "# Load validation and test datasets\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    val_data_dir,\n",
        "    image_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    label_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    test_data_dir,\n",
        "    image_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    label_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOHdU0lIMhNB",
        "outputId": "6d157954-3022-49a0-8354-269758af364d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2957 files belonging to 7 classes.\n",
            "Found 1028 files belonging to 7 classes.\n",
            "Found 1028 files belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print one of the training examples\n",
        "for images, labels in train_dataset.take(1):\n",
        "    print(\"Image shape:\", images[0].numpy().shape)\n",
        "    print(\"Label:\", labels[0].numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNOJtbJi_kEH",
        "outputId": "06330713-cc9d-43f9-d016-40b59fa475cd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: (128, 128, 3)\n",
            "Label: [0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load EfficientNetB0 with pre-trained ImageNet weights\n",
        "base_model = EfficientNetB0(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a new model on top\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(7, activation='softmax')  # 7 classes for 7 diseases\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "id": "X28FVc0AMjPJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4QYtHR5MpM_",
        "outputId": "6970abc9-fecf-4bc4-f1b5-d0bc91c06f9b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 468ms/step - accuracy: 0.3701 - loss: 1.6227 - val_accuracy: 0.6780 - val_loss: 0.9064\n",
            "Epoch 2/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 234ms/step - accuracy: 0.6264 - loss: 1.0190 - val_accuracy: 0.7490 - val_loss: 0.7604\n",
            "Epoch 3/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - accuracy: 0.6912 - loss: 0.8751 - val_accuracy: 0.7947 - val_loss: 0.6350\n",
            "Epoch 4/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 259ms/step - accuracy: 0.7230 - loss: 0.7673 - val_accuracy: 0.8035 - val_loss: 0.5832\n",
            "Epoch 5/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 252ms/step - accuracy: 0.7624 - loss: 0.6763 - val_accuracy: 0.8298 - val_loss: 0.5041\n",
            "Epoch 6/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 251ms/step - accuracy: 0.7655 - loss: 0.6374 - val_accuracy: 0.8541 - val_loss: 0.4331\n",
            "Epoch 7/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 248ms/step - accuracy: 0.7925 - loss: 0.5650 - val_accuracy: 0.8609 - val_loss: 0.4081\n",
            "Epoch 8/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - accuracy: 0.8304 - loss: 0.4923 - val_accuracy: 0.8619 - val_loss: 0.3877\n",
            "Epoch 9/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 221ms/step - accuracy: 0.8258 - loss: 0.4928 - val_accuracy: 0.8677 - val_loss: 0.3783\n",
            "Epoch 10/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 233ms/step - accuracy: 0.8426 - loss: 0.4749 - val_accuracy: 0.8833 - val_loss: 0.3357\n",
            "Epoch 11/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 234ms/step - accuracy: 0.8401 - loss: 0.4710 - val_accuracy: 0.8794 - val_loss: 0.3309\n",
            "Epoch 12/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 234ms/step - accuracy: 0.8448 - loss: 0.4302 - val_accuracy: 0.9047 - val_loss: 0.2941\n",
            "Epoch 13/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 230ms/step - accuracy: 0.8574 - loss: 0.4161 - val_accuracy: 0.9008 - val_loss: 0.3002\n",
            "Epoch 14/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 255ms/step - accuracy: 0.8579 - loss: 0.4041 - val_accuracy: 0.9154 - val_loss: 0.2636\n",
            "Epoch 15/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 241ms/step - accuracy: 0.8730 - loss: 0.3564 - val_accuracy: 0.9095 - val_loss: 0.2683\n",
            "Epoch 16/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - accuracy: 0.8850 - loss: 0.3565 - val_accuracy: 0.9095 - val_loss: 0.2809\n",
            "Epoch 17/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 227ms/step - accuracy: 0.8879 - loss: 0.3475 - val_accuracy: 0.9193 - val_loss: 0.2476\n",
            "Epoch 18/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 228ms/step - accuracy: 0.8723 - loss: 0.3552 - val_accuracy: 0.9232 - val_loss: 0.2183\n",
            "Epoch 19/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 231ms/step - accuracy: 0.8813 - loss: 0.3505 - val_accuracy: 0.9309 - val_loss: 0.2030\n",
            "Epoch 20/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 241ms/step - accuracy: 0.8983 - loss: 0.3135 - val_accuracy: 0.9232 - val_loss: 0.2207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the base model for fine-tuning\n",
        "base_model.trainable = True\n",
        "\n",
        "# Re-compile the model with a lower learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fine-tune the model\n",
        "history_fine = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Poj1cpD9MsB9",
        "outputId": "1e49cf03-c7fb-417d-a232-2ca8705b783c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 788ms/step - accuracy: 0.3611 - loss: 2.8921 - val_accuracy: 0.7305 - val_loss: 0.8179\n",
            "Epoch 2/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 267ms/step - accuracy: 0.4128 - loss: 2.4135 - val_accuracy: 0.6051 - val_loss: 1.3244\n",
            "Epoch 3/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 247ms/step - accuracy: 0.4468 - loss: 2.2573 - val_accuracy: 0.5574 - val_loss: 1.4652\n",
            "Epoch 4/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 264ms/step - accuracy: 0.4869 - loss: 1.9416 - val_accuracy: 0.5496 - val_loss: 1.4721\n",
            "Epoch 5/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 247ms/step - accuracy: 0.5078 - loss: 1.8785 - val_accuracy: 0.5720 - val_loss: 1.4188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model saved during training\n",
        "model.load_weights('best_model.keras')\n",
        "\n",
        "# Evaluate on the test dataset\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykeRZVnM-94g",
        "outputId": "ecb131fa-60f0-4ccf-eae4-64fd65743d2f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 432 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 10s/step - accuracy: 0.9444 - loss: 0.1584\n",
            "Test accuracy: 0.9339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model for later deployment with Streamlit\n",
        "model.save('teeth_disease_classifier.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wozQG_mk_BKy",
        "outputId": "d8f8ffec-047a-4b0e-a33f-981ea422fb4f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "\n",
        "# Load the model\n",
        "# model = tf.keras.models.load_model('mnist_classifier.h5')\n",
        "\n",
        "# Define a function to preprocess the image\n",
        "def preprocess_image(image):\n",
        "    size = (28, 28)  # MNIST images are 28x28\n",
        "    image = ImageOps.grayscale(image)\n",
        "    image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "    image = np.asarray(image)\n",
        "    image = image / 255.0\n",
        "    image = np.expand_dims(image, axis=-1)  # Add channel dimension\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    return image\n",
        "\n",
        "# Streamlit app\n",
        "st.write(\"# Disease Classifier\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=\"jpg\")\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption='Uploaded Image', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Classifying...\")\n",
        "\n",
        "    # Preprocess the image\n",
        "    img = preprocess_image(image)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(img)\n",
        "    st.write(f\"Prediction: {np.argmax(prediction)}\")"
      ],
      "metadata": {
        "id": "EmByFXcn3060"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to run Streamlit but u should do it from vscode 3l4an y4t8l\n",
        "# streamlit run app.py\n",
        "#"
      ],
      "metadata": {
        "id": "onxGwaCGyOEW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}